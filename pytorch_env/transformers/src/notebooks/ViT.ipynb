{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento imagenes SAR empleando transformers\n",
    "\n",
    "Se emplearon 2 arquitecturas para la restauracion de imagenes y reduccion de ruido implementando los siguientes papers:\n",
    "\n",
    "- [Restormer: Efficient Transformer for High-Resolution Image Restoration](https://arxiv.org/pdf/2111.09881)\n",
    "- [Uformer: A General U-Shaped Transformer for Image Restoration](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Uformer_A_General_U-Shaped_Transformer_for_Image_Restoration_CVPR_2022_paper.pdf)\n",
    "\n",
    "El archivo tiene la siguiente arquitectura:\n",
    "\n",
    "- [Restormer](#Restormer)\n",
    "\n",
    "  - [Entrenamiento](#r-entrenamiento)\n",
    "  - [Cargar Modelo](#r-modelo)\n",
    "  - [Inferecias](#r-inferencias)\n",
    "  - [Metricas](#r-metricas)\n",
    "\n",
    "- [Uformer](#Uformer)\n",
    "\n",
    "  - [Entrenamiento](#u-entrenamiento)\n",
    "  - [Inferecias](#u-inferencias)\n",
    "  - [Metricas](#u-metricas)\n",
    "\n",
    "- [Metricas comparativas](#metricas-comparativas)\n",
    "- [Test](#test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".column {\n",
       "  float: left;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "/* Clear floats after the columns */\n",
       ".row:after {\n",
       "  content: \"\";\n",
       "  display: table;\n",
       "  clear: both;\n",
       "}\n",
       "</style>\n",
       "<div class=\"row\">\n",
       "  <div class=\"column\"><iframe src=../references/Wang_Uformer_A_General_U-Shaped_Transformer_for_Image_Restoration_CVPR_2022_paper.pdf width=700 height=700></iframe></div>\n",
       "  <div class=\"column\"><iframe src=../references/2111.09881v2.pdf width=700 height=700></div>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"<style>\n",
    ".column {\n",
    "  float: left;\n",
    "  width: 50%;\n",
    "}\n",
    "\n",
    "/* Clear floats after the columns */\n",
    ".row:after {\n",
    "  content: \"\";\n",
    "  display: table;\n",
    "  clear: both;\n",
    "}\n",
    "</style>\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\"><iframe src=../references/Wang_Uformer_A_General_U-Shaped_Transformer_for_Image_Restoration_CVPR_2022_paper.pdf width=700 height=700></iframe></div>\n",
    "  <div class=\"column\"><iframe src=../references/2111.09881v2.pdf width=700 height=700></div>\n",
    "</div>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable de la carpeta principal\n",
    "\n",
    "Para ejecutar este archivo se debe de _**reemplazar la variable root_folder con la ruta de donde se descargo el repositorio**_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root_folder = Path(\"/home/arthemis/Documents/pytorch_env/pytorch_env/transformers/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restormer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](../../references/restormer.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento <a id='r-entrenamiento'></a>\n",
    "\n",
    "Los parametros de configuracion estan ubicados en el siguiente archivo:\n",
    "\n",
    "- [Configuracion](../data/config/config.yml)\n",
    "\n",
    "La siguiente celda es la encargada de ejecutar el entrenamiento del modelo **Restormer**. ⚠️ Solo se debe de manipular el archivo _config.yaml_.\n",
    "\n",
    "```yaml\n",
    "# general settings\n",
    "...\n",
    "...\n",
    "num_gpu: 1 # ----> Cambiar a 0 si se va a emplear CPU\n",
    "...\n",
    "...\n",
    "preprocessing:\n",
    "  image-path-raw: \"ruta de la carpeta que contiene las carpetas con las imagenes GTruth y Noisy\"\n",
    "  output: \"ruta de la carpeta que contiene las carpetas de imagenes aumentadas GTruth y Noisy\"\n",
    "  train-split-percentage: 0.8 # ---->  indica que el 80% de las imágenes del conjunto de datos se utilizarán para entrenar el modelo de machine learning. El 20% restante se reservará para evaluar el rendimiento del modelo en datos que no ha visto durante el entrenamiento.\n",
    "...\n",
    "...\n",
    "datasets:\n",
    "  train:\n",
    "    prefetch_mode: cuda # para GPU usar cuda, si se va a entrenar sin GPU usar cpu\n",
    "...\n",
    "...\n",
    "path:\n",
    "  pretrain_network_g: Ruta del modelo pre-entrenado(...basicsr/gaussian_gray_denoising_blind.pth)\n",
    "  ...\n",
    "  resume_state: ~ # Ruta del ultimo estado que se quiere usar para continuar el entrenamiento\n",
    "  experiments_root: Ruta donde se guardan archivos temporales durante el entrenamiento(.../src/visualization/temp)\n",
    "  ...\n",
    "  models: Ruta donde se guardaran los modelos de entramiento (.../src/data/model)\n",
    "  training_states: Ruta donde se guardan los estados del entrenamiento [\"metadata\"] (.../src/data/model/training_states)\n",
    "  ...\n",
    "  ...\n",
    "  ...\n",
    "train:\n",
    "  ...\n",
    "  ...\n",
    "  ...\n",
    "  pixel_opt:\n",
    "      type: PSNRLoss # Configuracion del tipo de perdida con el cual se va a entrenar el modelo, se pueden usar PSNRLoss, CharbonnierLoss y L1Loss\n",
    "  ...\n",
    "  ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se ejecuta esta celda, se inicia el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "wd = os.getcwd()\n",
    "os.chdir(\"../../\")\n",
    "%run basicsr/train.py\n",
    "os.chdir(wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar Modelo Entrenado <a id='r-modelo'></a>\n",
    "\n",
    "Los modelos que se pueden emplear en esta celda deben de estar previamente entrenados y contar con unas de las siguientes perdidas:\n",
    "- PSNR\n",
    "- CHARBONNIER\n",
    "- L1LOSS\n",
    "\n",
    "```python\n",
    "class ModelsName(str, Enum):\n",
    "    \"\"\"Clase Enum para escoger tipo de perdida para el modelo Restormer\"\"\"\n",
    "    PSNR = \"PSNR\"\n",
    "    CHARBONNIER = \"CharbonierLoss\"\n",
    "    L1LOSS = \"L1Loss_0_99\"\n",
    "\n",
    "\"\"\"Cargar de la siguiente manera, ecoger solo una perdida.\"\"\"\n",
    "# Ejemplo PSRN\n",
    "model_name = ModelsName.PSNR.value\n",
    "# Charbonnier\n",
    "model_name = ModelsName.CHARBONNIER.value\n",
    "# L1LOSS\n",
    "model_name = ModelsName.L1LOSS.value\n",
    "\n",
    "\n",
    "weights, parameters = get_weights_and_parameters(model_name)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PSNR (Peak Signal-to-Noise Ratio)**\n",
    "\n",
    "- El PSNR se calcula como el logaritmo base 10 de la relación entre la máxima potencia posible de la señal y la potencia del ruido de fondo. Matemáticamente, se expresa como:\n",
    "\n",
    "$ PSNR = 10 \\log\\_{10}( \\frac{\\text{MAX PIXEL VALUE}^2 }{MSE} ) $\n",
    "\n",
    "Donde:\n",
    "\n",
    "- MAX PIXEL VALUE es el valor máximo posible para un píxel (por ejemplo, 255 para imágenes de 8 bits)\n",
    "- MSE es el error cuadrático medio (Mean Squared Error) entre las imágenes original y reconstruida\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "- Fácil de interpretar y comprender.\n",
    "- Ampliamente utilizada y aceptada en la comunidad de investigación de imágenes.\n",
    "\n",
    "Desventajas:\n",
    "\n",
    "- Sensible a cambios en la luminosidad global de la imagen.\n",
    "- No tiene en cuenta la percepción visual humana.\n",
    "\n",
    "**Charbonnier Loss**\n",
    "\n",
    "La función de pérdida Charbonnier, también conocida como \" pérdida robusta de L1\", es una alternativa al PSNR que ofrece mayor robustez a valores atípicos (outliers) en los datos. En lugar de penalizar linealmente los errores, la pérdida Charbonnier aplica una penalización suave, lo que la hace menos sensible a picos de ruido.\n",
    "\n",
    "$ CharbonnierLoss = \\alpha \\cdot \\sqrt{(x^2 + \\epsilon^2)} + (1 - \\alpha) \\cdot L1\\_{Loss}(x) $\n",
    "\n",
    "Donde:\n",
    "\n",
    "- x es la diferencia entre los valores de píxeles correspondientes en las imágenes original y reconstruida\n",
    "- alpha es un factor de ponderación entre la penalización suave y la penalización L1 (típicamente entre 0 y 1)\n",
    "- epsilon es un pequeño valor positivo que evita la división por cero\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "- Robusta a valores atípicos en los datos.\n",
    "- Puede producir imágenes con mayor nitidez y detalles.\n",
    "\n",
    "Desventajas:\n",
    "\n",
    "- Cálculo ligeramente más complejo que el PSNR.\n",
    "- La elección del parámetro alpha puede afectar significativamente el resultado.\n",
    "\n",
    "**L1 Loss (L1 Loss)**\n",
    "\n",
    "La función de pérdida L1 (L1 Loss), también conocida como \"pérdida absoluta\", es una medida simple y directa de la diferencia entre los valores de píxeles correspondientes en las imágenes original y reconstruida. Se calcula como la suma de los valores absolutos de las diferencias de píxeles.\n",
    "\n",
    "La función de pérdida L1 se define como:\n",
    "\n",
    "$ L1\\_{Loss} = sum(abs(x)) $\n",
    "\n",
    "Donde:\n",
    "\n",
    "- x es la diferencia entre los valores de píxeles correspondientes en las imágenes original y reconstruida\n",
    "- abs() es la función valor absoluto\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "- Cálculo simple y eficiente.\n",
    "- Robusta a valores atípicos en los datos.\n",
    "\n",
    "Desventajas:\n",
    "\n",
    "- No tiene en cuenta la percepción visual humana.\n",
    "- Puede producir imágenes borrosas o con artefactos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Celda en la cual se genera la funcion para obtener los pesos de los diferentes modelos entrenados.\n",
    "*__Solo correr esta celda, no se debe de modificar nada.__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from runpy import run_path\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "# Cambiar cantidad de epoca de los pesos\n",
    "def get_weights_and_parameters(\n",
    "\tmodel: str, folder_weigths: Path | str\n",
    ") -> dict[str, list[Path] | list[int]]:\n",
    "\t# Si se quiere correr otro modelo se requiere cambiar el path\n",
    "\tmodels = {\n",
    "\t\t\"CharbonierLoss\": {\n",
    "\t\t\t\"weights_available\": (weights_available := list(range(4000, 88000, 4000))),\n",
    "\t\t\t\"path\": [\n",
    "\t\t\t\tPath(f\"{folder_weigths}/CharbonierLoss/net_g_{w}.pth\")\n",
    "\t\t\t\tfor w in weights_available\n",
    "\t\t\t],\n",
    "\t\t},\n",
    "\t\t\"L1Loss_0_99\": {\n",
    "\t\t\t\"weights_available\": (weights_available := list(range(4000, 84000, 4000))),\n",
    "\t\t\t\"path\": [\n",
    "\t\t\t\tPath(f\"{folder_weigths}/L1Loss_0_99/net_g_{w}.pth\")\n",
    "\t\t\t\tfor w in weights_available\n",
    "\t\t\t],\n",
    "\t\t},\n",
    "\t\t\"PSNR\": {\n",
    "\t\t\t\"weights_available\": (weights_available := list(range(4000, 104000, 4000))),\n",
    "\t\t\t\"path\": [\n",
    "\t\t\t\tPath(f\"{folder_weigths}/PSNR/net_g_{w}.pth\") for w in weights_available\n",
    "\t\t\t],\n",
    "\t\t},\n",
    "\t}\n",
    "\n",
    "\treturn models[model]\n",
    "\n",
    "\n",
    "class ModelsName(str, Enum):\n",
    "\t\"\"\"Clase Enum para escoger tipo de perdida para el modelo Restormer\"\"\"\n",
    "\n",
    "\tPSNR = \"PSNR\"\n",
    "\tCHARBONNIER = \"CharbonierLoss\"\n",
    "\tL1LOSS = \"L1Loss_0_99\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Definicion de rutas de pesos y scripts_\n",
    "\n",
    "- folder_weigths_root : Ruta donde se encuetran los pesos para el modelo de Restormer\n",
    "- model_path_root : Ruta donde se encuentra el script de ejecucion para cargar la arquitectura del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Restormer(\n",
       "  (patch_embed): OverlapPatchEmbed(\n",
       "    (proj): Conv2d(1, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (encoder_level1): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
       "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
       "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
       "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
       "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down1_2): Downsample(\n",
       "    (body): Sequential(\n",
       "      (0): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): PixelUnshuffle(downscale_factor=2)\n",
       "    )\n",
       "  )\n",
       "  (encoder_level2): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2_3): Downsample(\n",
       "    (body): Sequential(\n",
       "      (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): PixelUnshuffle(downscale_factor=2)\n",
       "    )\n",
       "  )\n",
       "  (encoder_level3): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3_4): Downsample(\n",
       "    (body): Sequential(\n",
       "      (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): PixelUnshuffle(downscale_factor=2)\n",
       "    )\n",
       "  )\n",
       "  (latent): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
       "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
       "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
       "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
       "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
       "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
       "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
       "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
       "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up4_3): Upsample(\n",
       "    (body): Sequential(\n",
       "      (0): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): PixelShuffle(upscale_factor=2)\n",
       "    )\n",
       "  )\n",
       "  (reduce_chan_level3): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (decoder_level3): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3_2): Upsample(\n",
       "    (body): Sequential(\n",
       "      (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): PixelShuffle(upscale_factor=2)\n",
       "    )\n",
       "  )\n",
       "  (reduce_chan_level2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (decoder_level2): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2_1): Upsample(\n",
       "    (body): Sequential(\n",
       "      (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): PixelShuffle(upscale_factor=2)\n",
       "    )\n",
       "  )\n",
       "  (decoder_level1): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (refinement): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output): Conv2d(96, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_weigths_root = root_folder / \"src/data/model\"\n",
    "parameters = {\n",
    "\t\"inp_channels\": 1,\n",
    "\t\"out_channels\": 1,\n",
    "\t\"dim\": 48,\n",
    "\t\"num_blocks\": [4, 6, 6, 8],\n",
    "\t\"num_refinement_blocks\": 4,\n",
    "\t\"heads\": [1, 2, 4, 8],\n",
    "\t\"ffn_expansion_factor\": 2.66,\n",
    "\t\"bias\": False,\n",
    "\t\"LayerNorm_type\": \"BiasFree\",\n",
    "\t\"dual_pixel_task\": False,\n",
    "}\n",
    "model_name = (\n",
    "\tModelsName.L1LOSS.value\n",
    ")  # ---> Este es el valor a modificar segun lo explicado anteriormente\n",
    "weights = get_weights_and_parameters(model_name, folder_weigths_root)\n",
    "\n",
    "# Cargar arquitectura del modelo\n",
    "model_path_root = root_folder / \"basicsr\"\n",
    "load_arch = run_path(\n",
    "\tos.path.join(model_path_root, \"models\", \"archs\", \"restormer_arch.py\")\n",
    ")\n",
    "model = load_arch[\"Restormer\"](**parameters)\n",
    "if torch.cuda.is_available():\n",
    "  model.cuda()\n",
    "else:\n",
    "  model.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferecias <a id='r-inferencias'></a>\n",
    "Generacion de imagenes restauradas (menor ruidos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Definicion de rutas_\n",
    "\n",
    "- __input_dir__ : Directorio donde se almacenas las imagenes Ground Truth para validacion\n",
    "- __noisy_dir__ : Directorio donde se almacenan las imagenes con Ruido o en su defecto sobre las cuales de hacen las predicciones\n",
    "- __out_dir__ : Directorio donde se almacenan la salida del modelo, tanto las imagenes como las metricas\n",
    "\n",
    "Si se requiere calcular las metricas poner en `True` la variable metrics_flag. Esta variable por defecto se encuentra en `True`.\n",
    "Nota: \n",
    "Seleccionar el nombre de las imagenes que desea hacer la inferencia, estas imagenes deben de existir en las carpetas __src/data/validation_data_report__ y __src/images__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import float64\n",
    "from collections import defaultdict\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "import json\n",
    "\n",
    "input_dir = root_folder / \"src/data/validation_data_report\"\n",
    "noisy_dir = root_folder / \"src/images\"\n",
    "out_dir = root_folder / f\"src/data/model/{model_name}/images\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Listado de imagenes seleccionadas en base al paper\n",
    "# files = ['0_1024', '5120_19456','5120_19968','5120_20480']\n",
    "# files = ['0_1024', '5120_19456', '5120_512', '5632_25088', '5632_18944', '5632_11776', '5120_20992', '5120_3072', '5120_1536', '5120_17408', '5120_24064', '5632_7680']\n",
    "files = [\"2560_22016_Tokyo\", \"2560_23552_Tokyo\", \"0_512\", \"0_1024\", \"0_1536\"]\n",
    "\n",
    "\n",
    "img_multiple_of = 8\n",
    "metrics_flag = True\n",
    "\n",
    "metrics = defaultdict(list[dict[str, float | str | float64]])\n",
    "with torch.no_grad():\n",
    "    for weight, index in zip(weights[\"path\"], weights[\"weights_available\"]):\n",
    "        checkpoint = torch.load(weight)\n",
    "        model.load_state_dict(checkpoint[\"params\"])\n",
    "        model.eval()\n",
    "        for filepath in tqdm(files):\n",
    "            torch.cuda.ipc_collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            # im_path: Path = noisy_dir / f\"{filepath}.png\"\n",
    "            im_path: Path = noisy_dir / f\"{filepath}.tiff\"\n",
    "            og = cv2.imread(im_path.as_posix(), -1)\n",
    "            img = cv2.cvtColor(og, cv2.COLOR_BGR2GRAY)\n",
    "            img_ = np.reshape(img, (512, 512, 1))\n",
    "            if torch.cuda.is_available():\n",
    "                input_ = (\n",
    "                    torch.from_numpy(img_).float().permute(2, 0, 1).unsqueeze(0).cuda()\n",
    "                )\n",
    "            else:\n",
    "                input_ = torch.from_numpy(img_).float().permute(2, 0, 1).unsqueeze(0).cpu()\n",
    "            h, w = input_.shape[2], input_.shape[3]\n",
    "            H, W = (\n",
    "                ((h + img_multiple_of) // img_multiple_of) * img_multiple_of,\n",
    "                ((w + img_multiple_of) // img_multiple_of) * img_multiple_of,\n",
    "            )\n",
    "            padh = H - h if h % img_multiple_of != 0 else 0\n",
    "            padw = W - w if w % img_multiple_of != 0 else 0\n",
    "            input_ = F.pad(input_, (0, padw, 0, padh), \"reflect\")\n",
    "            restored = model(input_)\n",
    "\n",
    "            # Unpad the output\n",
    "            restored = restored[:, :, :h, :w]\n",
    "            restored = restored.permute(0, 2, 3, 1).cpu().detach().numpy()\n",
    "            restored = np.squeeze(restored[0])\n",
    "\n",
    "            max_retormer = np.max(restored)\n",
    "            min_retormer = np.min(restored)\n",
    "            if metrics_flag:\n",
    "                val_im_path: Path = input_dir / f\"{filepath}.tiff\"\n",
    "                val_og = cv2.imread(val_im_path.as_posix(),-1)\n",
    "                val_img = cv2.cvtColor(val_og, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                metrics[f\"model_{index}\"].append({\n",
    "                f\"file_{filepath}\": \"\",\n",
    "                \"psnr\": psnr(val_img.astype(np.float32), restored, data_range=max_retormer - min_retormer),\n",
    "                \"ssim\": ssim(val_img.astype(np.float32), restored, data_range=max_retormer - min_retormer),\n",
    "                \"mse\": mse(val_img.astype(np.float32), restored)\n",
    "                })\n",
    "            filename = os.path.split(input_dir)[-1]\n",
    "            cv2.imwrite(os.path.join(out_dir, f\"{filepath}_{index}.png\"), restored)\n",
    "save_dir_metrics = out_dir / \"\".join((model_name, \".json\"))\n",
    "# json.dump(metrics,save_dir_metrics.open(\"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metricas <a id='r-metricas'></a>\n",
    "\n",
    "\n",
    "En la siguiente celda se calcula cual es el mejor modelo entrenado segun la perdida escogida. Para poder ejecutar esta celda se debe de haber ejecutado la anterior celda con la bandera metrics_flag en `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_76000\n"
     ]
    }
   ],
   "source": [
    "def calculate_best_model(data):\n",
    "\t\"\"\"\n",
    "\tAnalyzes a JSON structure containing model performance data and identifies\n",
    "\tthe model with the best overall performance based on:\n",
    "\t    - Lowest PSNR (Peak Signal-to-Noise Ratio)\n",
    "\t    - Highest SSIM (Structural Similarity Index Measure)\n",
    "\t    - Lowest MSE (Mean Squared Error)\n",
    "\n",
    "\tArgs:\n",
    "\t    data (dict): A dictionary representing the JSON data containing\n",
    "\t                 model performance information.\n",
    "\n",
    "\tReturns:\n",
    "\t    str: The name of the model with the best overall performance.\n",
    "\t\"\"\"\n",
    "\n",
    "\tbest_model = None\n",
    "\tbest_score = float(\"inf\")  # Initialize with positive infinity\n",
    "\n",
    "\tfor model_name, model_data in data.items():\n",
    "\t\tfor entry in model_data:\n",
    "\t\t\tscore = entry[\"psnr\"] + (1 - entry[\"ssim\"]) + entry[\"mse\"]\n",
    "\t\t\t# Combine PSNR, SSIM (inverted), and MSE into a single score\n",
    "\n",
    "\t\t\tif score < best_score:\n",
    "\t\t\t\tbest_model = model_name\n",
    "\t\t\t\tbest_score = score\n",
    "\n",
    "\treturn best_model\n",
    "\n",
    "\n",
    "metrics = json.load(save_dir_metrics.open(\"r\"))\n",
    "print(calculate_best_model(metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](../../Uformer/fig/Uformer.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento <a id='u-entrenamiento'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Ruta para ejecucion_\n",
    "\n",
    "- train_workers : \"Ruta de las imagenes Ground Truth\"\n",
    "- val_dir: \"Ruta de la imagenes Noisy\",\n",
    "- gpu: Numero de la GPU para ejecucion, por defecto empieza en la posicion cero\n",
    "\n",
    "Ejecutar siguiente celda para realizar el entramiento del UFormer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "wd = os.getcwd()\n",
    "os.chdir(\"../Uformer\")\n",
    "! poetry run train/train_denoise.py --train_dir /home/arthemis/Documents/pytorch_env/pytorch_env/transformers_ruben/src/data/transformed_data/GTruth/ --gpu 0 --val_dir /home/arthemis/Documents/pytorch_env/pytorch_env/transformers_ruben/src/data/transformed_data/val\n",
    "os.chdir(wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferecias <a id='u-inferencias'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Ruta para ejecucion_\n",
    "\n",
    "- input_dir : \"Ruta de las imagenes Noisy\"\n",
    "- result_dir: \"Ruta donde se guardan las imagenes\",\n",
    "- weights: Ruta de los pesos del modelo entrenado en la celda anterior\n",
    "\n",
    "En la siguiente celda se realiza la inferencia de las imagenes. ⚠️ Para ejecutar esta celda es necesario tener una GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You choose Uformer_B...\n",
      "/home/arthemis/.cache/pypoetry/virtualenvs/pytorch-env-VZ5w7g_q-py3.10/lib/python3.10/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "===>Testing using weights:  /home/arthemis/Documents/pytorch_env/pytorch_env/transformers/Uformer/logs/denoising/SIDD/Uformer_B_/models/model_best.pth\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]0\n",
      "0_1024\n",
      " 20%|█████████                                    | 1/5 [00:00<00:02,  1.48it/s]1\n",
      "0_1536\n",
      " 40%|██████████████████                           | 2/5 [00:00<00:01,  2.68it/s]2\n",
      "0_512\n",
      " 60%|███████████████████████████                  | 3/5 [00:00<00:00,  3.62it/s]3\n",
      "2560_22016_Tokyo\n",
      " 80%|████████████████████████████████████         | 4/5 [00:01<00:00,  4.34it/s]4\n",
      "2560_23552_Tokyo\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:01<00:00,  3.75it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "wd = os.getcwd()\n",
    "os.chdir(\"../Uformer\")\n",
    "! poetry run python3 test/test_dnd.py --input_dir /home/arthemis/Documents/pytorch_env/pytorch_env/transformers/src/images --result_dir ./results/denoising/DND/ --weights /home/arthemis/Documents/pytorch_env/pytorch_env/transformers/Uformer/logs/denoising/SIDD/Uformer_B_/models/model_best.pth\n",
    "os.chdir(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metricas <a id='u-metricas'></a>\n",
    "\n",
    "En la siguiente celda se calculan las metricas del modelo Uformer. Para ejecutar esta celda se deben de tener las imagenes inferidas por la celda anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "from collections import defaultdict\n",
    "from numpy import float64\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def metrics(\n",
    "\tgt_dir: Path = root_folder / \"src/data/validation_data_report\",\n",
    "\tinput_dir: Path = root_folder / \"Uformer/results/denoising/DND/png\",\n",
    "\tfiles: list[str] = [\"0_1024\", \"5120_19456\", \"5120_19968\", \"5120_20480\"],\n",
    "):\n",
    "\tmetrics_uformer = defaultdict(list[dict[str, float | str | float64]])\n",
    "\tfor filepath in tqdm(files):\n",
    "\t\tim_path = gt_dir / f\"{filepath}.tiff\"\n",
    "\t\tog = cv2.imread(im_path.as_posix(), -1)\n",
    "\t\timg = cv2.cvtColor(og, cv2.COLOR_BGR2GRAY)\n",
    "\t\t# img_ = np.reshape(img, (512, 512, 1))\n",
    "\t\trestored_img = input_dir / f\"{filepath}.png\"\n",
    "\t\trestored = cv2.imread(restored_img.as_posix(), -1)\n",
    "\t\trestored = cv2.cvtColor(restored, cv2.COLOR_BGR2GRAY)\n",
    "\t\t# restored = np.reshape(img, (512, 512, 1))\n",
    "\t\tmax_retormer: float = np.max(restored)\n",
    "\t\tmin_retormer: float = np.min(restored)\n",
    "\t\tmetrics_uformer[\"model\"].append(\n",
    "\t\t\t{\n",
    "\t\t\t\tf\"file_{filepath}\": \"\",\n",
    "\t\t\t\t\"psnr\": psnr(\n",
    "\t\t\t\t\timg.astype(np.float32),\n",
    "\t\t\t\t\trestored,\n",
    "\t\t\t\t\tdata_range=max_retormer - min_retormer,\n",
    "\t\t\t\t),\n",
    "\t\t\t\t\"ssim\": ssim(\n",
    "\t\t\t\t\timg.astype(np.float32),\n",
    "\t\t\t\t\trestored,\n",
    "\t\t\t\t\tdata_range=max_retormer - min_retormer,\n",
    "\t\t\t\t),\n",
    "\t\t\t\t\"mse\": mse(img.astype(np.float32), restored),\n",
    "\t\t\t}\n",
    "\t\t)\n",
    "\n",
    "\twith open(\"metrics_uformer.json\", \"w\") as json_file:\n",
    "\t\tjson.dump(metrics_uformer, json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
