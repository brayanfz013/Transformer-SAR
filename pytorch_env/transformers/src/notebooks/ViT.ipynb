{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporte imagenes SAR con empleando transformers\n",
    "\n",
    "Se emplearon 2 arquitecturas para la restauracion de imagenes y reduccion de ruido implementando los siguientes papers:\n",
    "\n",
    "- [Restormer: Efficient Transformer for High-Resolution Image Restoration](https://arxiv.org/pdf/2111.09881)\n",
    "- [Uformer: A General U-Shaped Transformer for Image Restoration](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Uformer_A_General_U-Shaped_Transformer_for_Image_Restoration_CVPR_2022_paper.pdf)\n",
    "\n",
    "El reporte consta de la exploracion de la siguiente arquitectura:\n",
    "\n",
    "- [Restormer](#Restormer)\n",
    "    - [Entrenamiento](#r-entrenamiento)\n",
    "    - [Cargar Modelo](#r-modelo)\n",
    "    - [Inferecias](#r-inferencias)\n",
    "    - [Metricas](#r-metricas)\n",
    "\n",
    "- [Uformer](#Uformer)\n",
    "    - [Entrenamiento](#u-entrenamiento)\n",
    "    - [Inferecias](#u-inferencias)\n",
    "    - [Metricas](#u-metricas)\n",
    "\n",
    "- [Metricas comparativas](#metricas-comparativas)\n",
    "- [Test](#test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"<style>\n",
    ".column {\n",
    "  float: left;\n",
    "  width: 50%;\n",
    "}\n",
    "\n",
    "/* Clear floats after the columns */\n",
    ".row:after {\n",
    "  content: \"\";\n",
    "  display: table;\n",
    "  clear: both;\n",
    "}\n",
    "</style>\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\"><iframe src=../references/Wang_Uformer_A_General_U-Shaped_Transformer_for_Image_Restoration_CVPR_2022_paper.pdf width=700 height=700></iframe></div>\n",
    "  <div class=\"column\"><iframe src=../references/2111.09881v2.pdf width=700 height=700></div>\n",
    "</div>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable de la carpeta principal\n",
    "A a hora de ejercutar este archivo, por favor reemplazar esta variable con la ruta de donde se descargo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "root_folder = Path(\"/home/arthemis/Documents/pytorch_env/pytorch_env/transformers/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restormer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](../../references/restormer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento <a id='r-entrenamiento'></a> \n",
    "\n",
    "Los parametro de configuracion estan ubicados en el siguiente archivo:\n",
    "- [Configuracion](../data/config/config.yml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modify the file in /home/arthemis/Documents/pytorch_env/pytorch_env/transformers_ruben/src/data/config/config.yml\n",
    "# Restormer\n",
    "import os\n",
    "wd = os.getcwd()\n",
    "os.chdir(\"../../\")\n",
    "%run basicsr/train.py\n",
    "os.chdir(wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar Modelo <a id='r-modelo'></a> \n",
    "\n",
    "A la hora de escoger un nuevo modelo entrenado con otra perdida,cambiar el valor de PSNR por CHARBONNIER o L1LOSS\n",
    "\n",
    "```python\n",
    "class ModelsName(str, Enum):\n",
    "    \"\"\"Clase Enum para escoger tipo de perdida para el modelo Restormer\"\"\"\n",
    "    PSNR = \"PSNR\"\n",
    "    CHARBONNIER = \"CharbonierLoss\"\n",
    "    L1LOSS = \"L1Loss_0_99\"\n",
    "\n",
    "# Ejemplo PSRN\n",
    "model_name = ModelsName.PSNR.value\n",
    "# Charbonnier\n",
    "model_name = ModelsName.CHARBONNIER.value\n",
    "# L1LOSS\n",
    "model_name = ModelsName.L1LOSS.value\n",
    "\n",
    "\n",
    "weights, parameters = get_weights_and_parameters(model_name)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PSNR (Peak Signal-to-Noise Ratio)**\n",
    "\n",
    "- El PSNR se calcula como el logaritmo base 10 de la relación entre la máxima potencia posible de la señal y la potencia del ruido de fondo. Matemáticamente, se expresa como:\n",
    "\n",
    "$ PSNR = 10 \\log_{10}( \\frac{\\text{MAX PIXEL VALUE}^2 }{MSE} ) $\n",
    "\n",
    "Donde:\n",
    "- MAX PIXEL VALUE es el valor máximo posible para un píxel (por ejemplo, 255 para imágenes de 8 bits)\n",
    "- MSE es el error cuadrático medio (Mean Squared Error) entre las imágenes original y reconstruida\n",
    "\n",
    "Ventajas:\n",
    "- Fácil de interpretar y comprender.\n",
    "- Ampliamente utilizada y aceptada en la comunidad de investigación de imágenes.\n",
    "\n",
    "Desventajas:\n",
    "- Sensible a cambios en la luminosidad global de la imagen.\n",
    "- No tiene en cuenta la percepción visual humana.\n",
    "\n",
    "**Charbonnier Loss**\n",
    "\n",
    "La función de pérdida Charbonnier, también conocida como \" pérdida robusta de L1\", es una alternativa al PSNR que ofrece mayor robustez a valores atípicos (outliers) en los datos. En lugar de penalizar linealmente los errores, la pérdida Charbonnier aplica una penalización suave, lo que la hace menos sensible a picos de ruido.\n",
    "\n",
    "$ CharbonnierLoss = \\alpha \\cdot \\sqrt{(x^2 + \\epsilon^2)} + (1 - \\alpha) \\cdot L1_{Loss}(x) $\n",
    "\n",
    "Donde:\n",
    "\n",
    "- x es la diferencia entre los valores de píxeles correspondientes en las imágenes original y reconstruida\n",
    "- alpha es un factor de ponderación entre la penalización suave y la penalización L1 (típicamente entre 0 y 1)\n",
    "- epsilon es un pequeño valor positivo que evita la división por cero\n",
    "\n",
    "Ventajas:\n",
    "- Robusta a valores atípicos en los datos.\n",
    "- Puede producir imágenes con mayor nitidez y detalles.\n",
    "\n",
    "Desventajas:\n",
    "- Cálculo ligeramente más complejo que el PSNR.\n",
    "- La elección del parámetro alpha puede afectar significativamente el resultado.\n",
    "\n",
    "\n",
    "**L1 Loss (L1 Loss)**\n",
    "\n",
    "La función de pérdida L1 (L1 Loss), también conocida como \"pérdida absoluta\", es una medida simple y directa de la diferencia entre los valores de píxeles correspondientes en las imágenes original y reconstruida. Se calcula como la suma de los valores absolutos de las diferencias de píxeles.\n",
    "\n",
    "La función de pérdida L1 se define como:\n",
    "\n",
    "$ L1_{Loss} = sum(abs(x)) $\n",
    "\n",
    "Donde:\n",
    "\n",
    "- x es la diferencia entre los valores de píxeles correspondientes en las imágenes original y reconstruida\n",
    "- abs() es la función valor absoluto\n",
    "\n",
    "Ventajas:\n",
    "- Cálculo simple y eficiente.\n",
    "- Robusta a valores atípicos en los datos.\n",
    "\n",
    "Desventajas:\n",
    "- No tiene en cuenta la percepción visual humana.\n",
    "- Puede producir imágenes borrosas o con artefactos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from runpy import run_path\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "from enum import Enum\n",
    "\n",
    "# Cambiar cantidad de epoca de los pesos\n",
    "def get_weights_and_parameters(model: str, folder_weigths:  Path | str)-> dict[str, list[Path] | list[int]]:\n",
    "\n",
    "    # Si se quiere correr otro modelo se requiere cambiar el path\n",
    "    models = {\"CharbonierLoss\": {\n",
    "        \"weights_available\" : (weights_available:=list(range(4000, 88000, 4000))),\n",
    "        \"path\": [Path(f\"{folder_weigths}/CharbonierLoss/net_g_{w}.pth\") for w in weights_available]\n",
    "    },\n",
    "    \"L1Loss_0_99\":{\n",
    "        \"weights_available\" : (weights_available:=list(range(4000, 84000, 4000))),\n",
    "        \"path\": [Path(f\"{folder_weigths}/L1Loss_0_99/net_g_{w}.pth\") for w in weights_available]\n",
    "    },\n",
    "   \"PSNR\": {\n",
    "        \"weights_available\" : (weights_available:=list(range(4000, 104000, 4000))),\n",
    "        \"path\": [Path(f\"{folder_weigths}/PSNR/net_g_{w}.pth\") for w in weights_available]\n",
    "    }    \n",
    "    }\n",
    "    \n",
    "    return models[model]\n",
    "\n",
    "\n",
    "class ModelsName(str, Enum):\n",
    "    \"\"\"Clase Enum para escoger tipo de perdida para el modelo Restormer\"\"\"\n",
    "    PSNR = \"PSNR\"\n",
    "    CHARBONNIER = \"CharbonierLoss\"\n",
    "    L1LOSS = \"L1Loss_0_99\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Definicion de rutas de pesos y scripts*\n",
    "\n",
    "- folder_weigths_root : Ruta donde se encuetran los pesos para el modelo de Restormer\n",
    "- model_path_root : Ruta donde se encuentra el script de ejecucion para cargar la arquitectura del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Restormer(\n",
       "  (patch_embed): OverlapPatchEmbed(\n",
       "    (proj): Conv2d(1, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (encoder_level1): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
       "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
       "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
       "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
       "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down1_2): Downsample(\n",
       "    (body): Sequential(\n",
       "      (0): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): PixelUnshuffle(downscale_factor=2)\n",
       "    )\n",
       "  )\n",
       "  (encoder_level2): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2_3): Downsample(\n",
       "    (body): Sequential(\n",
       "      (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): PixelUnshuffle(downscale_factor=2)\n",
       "    )\n",
       "  )\n",
       "  (encoder_level3): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3_4): Downsample(\n",
       "    (body): Sequential(\n",
       "      (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): PixelUnshuffle(downscale_factor=2)\n",
       "    )\n",
       "  )\n",
       "  (latent): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
       "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
       "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
       "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
       "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
       "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
       "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
       "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
       "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up4_3): Upsample(\n",
       "    (body): Sequential(\n",
       "      (0): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): PixelShuffle(upscale_factor=2)\n",
       "    )\n",
       "  )\n",
       "  (reduce_chan_level3): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (decoder_level3): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
       "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3_2): Upsample(\n",
       "    (body): Sequential(\n",
       "      (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): PixelShuffle(upscale_factor=2)\n",
       "    )\n",
       "  )\n",
       "  (reduce_chan_level2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (decoder_level2): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2_1): Upsample(\n",
       "    (body): Sequential(\n",
       "      (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): PixelShuffle(upscale_factor=2)\n",
       "    )\n",
       "  )\n",
       "  (decoder_level1): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (refinement): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
       "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output): Conv2d(96, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_weigths_root = root_folder/ \"src/data/model\"\n",
    "parameters = {'inp_channels':1, 'out_channels':1, 'dim':48, 'num_blocks':[4,6,6,8], 'num_refinement_blocks':4, 'heads':[1,2,4,8], 'ffn_expansion_factor':2.66, 'bias':False, 'LayerNorm_type':'BiasFree', 'dual_pixel_task':False}\n",
    "model_name = ModelsName.L1LOSS.value\n",
    "weights = get_weights_and_parameters(model_name, folder_weigths_root)\n",
    "\n",
    "#Cargar arquitectura del modelo\n",
    "model_path_root = root_folder/ \"basicsr\"\n",
    "load_arch = run_path(os.path.join( model_path_root, \"models\", \"archs\",\"restormer_arch.py\"))\n",
    "model = load_arch['Restormer'](**parameters)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferecias  <a id='r-inferencias'></a> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Definicion de rutas*\n",
    "\n",
    "- input_dir : Directorio donde se almacenas las imagenes Ground Truth para validacion \n",
    "- noisy_dir : Directorio donde se almacenan las imagenes con Ruido o en su defecto sobre las cuales de hacen las predicciones\n",
    "- out_dir : Directorio donde se almacenan la salida del modelo, tanto las imagenes como las metricas\n",
    "\n",
    "\n",
    "**Nota:** Verificar el formato de las imagenes antes de ejecutar las celda siguiente dado se trabajo en PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.13it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.30it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.30it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.30it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.30it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.30it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.27it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  1.96it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  1.99it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  1.97it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.01it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.13it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.03it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.07it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.05it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.06it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.10it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.14it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.13it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from numpy import float64\n",
    "from collections import defaultdict\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "import json\n",
    "\n",
    "input_dir = root_folder / \"src/data/validation_data_report\"\n",
    "noisy_dir = root_folder /\"Uformer/images\"\n",
    "out_dir = root_folder / f\"src/data/model/{model_name}/images\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "#Listado de imagenes seleccionadas en base al paper \n",
    "# files = ['0_1024', '5120_19456','5120_19968','5120_20480']\n",
    "# files = ['0_1024', '5120_19456', '5120_512', '5632_25088', '5632_18944', '5632_11776', '5120_20992', '5120_3072', '5120_1536', '5120_17408', '5120_24064', '5632_7680']\n",
    "files = [\"2560_22016_Tokyo\", \"2560_23552_Tokyo\", \"0_512\", \"0_1024\", \"0_1536\"]\n",
    "\n",
    "img_multiple_of = 8\n",
    "\n",
    "metrics = defaultdict(list[dict[str, float | str | float64]])\n",
    "with torch.no_grad():\n",
    "    for weight, index in zip(weights[\"path\"], weights[\"weights_available\"]):\n",
    "        checkpoint = torch.load(weight)\n",
    "        model.load_state_dict(checkpoint[\"params\"])\n",
    "        model.eval()\n",
    "        for filepath in tqdm(files):\n",
    "            torch.cuda.ipc_collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            # im_path: Path = noisy_dir / f\"{filepath}.png\"\n",
    "            im_path: Path = noisy_dir / f\"{filepath}.tiff\"\n",
    "            og = cv2.imread(im_path.as_posix(),-1)\n",
    "            img = cv2.cvtColor(og, cv2.COLOR_BGR2GRAY)\n",
    "            img_ = np.reshape(img, (512, 512, 1))\n",
    "\n",
    "            input_ = torch.from_numpy(img_).float().permute(2, 0, 1).unsqueeze(0).cuda()\n",
    "            h, w = input_.shape[2], input_.shape[3]\n",
    "            H, W = (\n",
    "                ((h + img_multiple_of) // img_multiple_of) * img_multiple_of,\n",
    "                ((w + img_multiple_of) // img_multiple_of) * img_multiple_of,\n",
    "            )\n",
    "            padh = H - h if h % img_multiple_of != 0 else 0\n",
    "            padw = W - w if w % img_multiple_of != 0 else 0\n",
    "            input_ = F.pad(input_, (0, padw, 0, padh), \"reflect\")\n",
    "            restored = model(input_)\n",
    "\n",
    "            # Unpad the output\n",
    "            restored = restored[:, :, :h, :w]\n",
    "            restored = restored.permute(0, 2, 3, 1).cpu().detach().numpy()\n",
    "            restored = np.squeeze(restored[0])\n",
    "\n",
    "            max_retormer = np.max(restored)\n",
    "            min_retormer = np.min(restored)     \n",
    "            # val_im_path: Path = input_dir / f\"{filepath}.tiff\"\n",
    "            # val_og = cv2.imread(val_im_path.as_posix(),-1)\n",
    "            # val_img = cv2.cvtColor(val_og, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # metrics[f\"model_{index}\"].append({\n",
    "\t\t\t# \tf\"file_{filepath}\": \"\",\n",
    "\t\t\t# \t\"psnr\": psnr(val_img.astype(np.float32), restored, data_range=max_retormer - min_retormer),\n",
    "\t\t\t# \t\"ssim\": ssim(val_img.astype(np.float32), restored, data_range=max_retormer - min_retormer),\n",
    "\t\t\t# \t\"mse\": mse(val_img.astype(np.float32), restored)\n",
    "\t\t\t# })\n",
    "            filename = os.path.split(input_dir)[-1]\n",
    "            cv2.imwrite(os.path.join(out_dir, f\"{filepath}_{index}.png\"), restored)\n",
    "save_dir_metrics = out_dir / \"\".join((model_name,\".json\"))\n",
    "# json.dump(metrics,save_dir_metrics.open(\"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metricas  <a id='r-metricas'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_76000\n"
     ]
    }
   ],
   "source": [
    "def calculate_best_model(data):\n",
    "\t\"\"\"\n",
    "\tAnalyzes a JSON structure containing model performance data and identifies\n",
    "\tthe model with the best overall performance based on:\n",
    "\t    - Lowest PSNR (Peak Signal-to-Noise Ratio)\n",
    "\t    - Highest SSIM (Structural Similarity Index Measure)\n",
    "\t    - Lowest MSE (Mean Squared Error)\n",
    "\n",
    "\tArgs:\n",
    "\t    data (dict): A dictionary representing the JSON data containing\n",
    "\t                 model performance information.\n",
    "\n",
    "\tReturns:\n",
    "\t    str: The name of the model with the best overall performance.\n",
    "\t\"\"\"\n",
    "\n",
    "\tbest_model = None\n",
    "\tbest_score = float(\"inf\")  # Initialize with positive infinity\n",
    "\n",
    "\tfor model_name, model_data in data.items():\n",
    "\t\tfor entry in model_data:\n",
    "\t\t\tscore = entry[\"psnr\"] + (1 - entry[\"ssim\"]) + entry[\"mse\"]\n",
    "\t\t\t# Combine PSNR, SSIM (inverted), and MSE into a single score\n",
    "\n",
    "\t\t\tif score < best_score:\n",
    "\t\t\t\tbest_model = model_name\n",
    "\t\t\t\tbest_score = score\n",
    "\n",
    "\treturn best_model\n",
    "\n",
    "metrics = json.load(save_dir_metrics.open('r'))\n",
    "print(calculate_best_model(metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](../../Uformer/fig/Uformer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento <a id='u-entrenamiento'></a> \n",
    "\n",
    "Los parametro de configuracion estan ubicados en el siguiente archivo:\n",
    "- [Configuracion](../data/config/config.yml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ruta para ejecucion*\n",
    "- train_workers : \"Ruta de las imagenes Ground Truth\"\n",
    "- val_dir: \"Ruta de la imagenes Noisy\",\n",
    "- gpu: Numero de la GPU para ejecucion, por defecto empieza en la posicion cero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "wd = os.getcwd()\n",
    "os.chdir(\"../Uformer\")\n",
    "! poetry run train/train_denoise.py --train_dir /home/arthemis/Documents/pytorch_env/pytorch_env/transformers_ruben/src/data/transformed_data/GTruth/ --gpu 0 --val_dir /home/arthemis/Documents/pytorch_env/pytorch_env/transformers_ruben/src/data/transformed_data/val\n",
    "os.chdir(wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferecias  <a id='u-inferencias'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ruta para ejecucion*\n",
    "- input_dir : \"Ruta de las imagenes Noisy\"\n",
    "- result_dir: \"Ruta donde se guardan las imagenes\",\n",
    "- weights: Ruta de los pesos del modelo entrenado en la celda anterior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You choose Uformer_B...\n",
      "/home/arthemis/.cache/pypoetry/virtualenvs/pytorch-env-VZ5w7g_q-py3.10/lib/python3.10/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "===>Testing using weights:  /home/arthemis/Documents/pytorch_env/pytorch_env/transformers/Uformer/logs/denoising/SIDD/Uformer_B_/models/model_best.pth\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]0\n",
      "0_1024\n",
      " 20%|█████████                                    | 1/5 [00:00<00:02,  1.48it/s]1\n",
      "0_1536\n",
      " 40%|██████████████████                           | 2/5 [00:00<00:01,  2.68it/s]2\n",
      "0_512\n",
      " 60%|███████████████████████████                  | 3/5 [00:00<00:00,  3.62it/s]3\n",
      "2560_22016_Tokyo\n",
      " 80%|████████████████████████████████████         | 4/5 [00:01<00:00,  4.34it/s]4\n",
      "2560_23552_Tokyo\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:01<00:00,  3.75it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "wd = os.getcwd()\n",
    "os.chdir(\"../Uformer\")\n",
    "! poetry run python3 test/test_dnd.py --input_dir /home/arthemis/Documents/pytorch_env/pytorch_env/transformers/Uformer/images --result_dir ./results/denoising/DND/ --weights /home/arthemis/Documents/pytorch_env/pytorch_env/transformers/Uformer/logs/denoising/SIDD/Uformer_B_/models/model_best.pth\n",
    "os.chdir(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metricas <a id='u-metricas'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "from collections import defaultdict\n",
    "from numpy import float64\n",
    "from tqdm import tqdm\n",
    "\n",
    "def metrics(gt_dir: Path = root_folder / 'src/data/validation_data_report',\n",
    "            input_dir: Path = root_folder / \"Uformer/results/denoising/DND/png\",\n",
    "            files: list[str] = ['0_1024', '5120_19456','5120_19968','5120_20480']):\n",
    "\n",
    "    metrics_uformer = defaultdict(list[dict[str, float | str | float64]])\n",
    "    for filepath in tqdm(files):\n",
    "        im_path = gt_dir / f\"{filepath}.tiff\"\n",
    "        og = cv2.imread(im_path.as_posix(),-1)\n",
    "        img = cv2.cvtColor(og, cv2.COLOR_BGR2GRAY)\n",
    "        # img_ = np.reshape(img, (512, 512, 1))\n",
    "        restored_img = input_dir / f\"{filepath}.png\"\n",
    "        restored = cv2.imread(restored_img.as_posix(),-1)\n",
    "        restored = cv2.cvtColor(restored, cv2.COLOR_BGR2GRAY)\n",
    "        # restored = np.reshape(img, (512, 512, 1))\n",
    "        max_retormer: float = np.max(restored)\n",
    "        min_retormer: float = np.min(restored)\n",
    "        metrics_uformer[\"model\"].append({\n",
    "            f\"file_{filepath}\": \"\",\n",
    "            \"psnr\": psnr(img.astype(np.float32), restored, data_range=max_retormer - min_retormer),\n",
    "            \"ssim\": ssim(img.astype(np.float32), restored, data_range=max_retormer - min_retormer),\n",
    "            \"mse\": mse(img.astype(np.float32), restored)\n",
    "        })\n",
    "        \n",
    "\n",
    "\n",
    "    with open(\"metrics_uformer.json\",\"w\") as json_file:\n",
    "        json.dump(metrics_uformer,json_file)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
