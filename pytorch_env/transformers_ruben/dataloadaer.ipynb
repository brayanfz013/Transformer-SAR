{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "def create_dataloader(dataset: Dataset, dataset_opt: dict) -> DataLoader:\n",
    "    \"\"\"Create dataloader.\n",
    "\n",
    "    Args:\n",
    "        dataset (torch.utils.data.Dataset): Dataset.\n",
    "        dataset_opt (dict): Dataset options. It contains the following keys:\n",
    "            phase (str): 'train' or 'val'.\n",
    "            num_worker_per_gpu (int): Number of workers for each GPU.\n",
    "            batch_size_per_gpu (int): Training batch size for each GPU.\n",
    "        num_gpu (int): Number of GPUs. Used only in the train phase.\n",
    "            Default: 1.\n",
    "        dist (bool): Whether in distributed training. Used only in the train\n",
    "            phase. Default: False.\n",
    "        sampler (torch.utils.data.sampler): Data sampler. Default: None.\n",
    "        seed (int | None): Seed. Default: None\n",
    "    \"\"\"\n",
    "    phase = dataset_opt[\"phase\"]\n",
    "    if phase == \"train\":\n",
    "        dataloader_args = dict(\n",
    "            dataset=dataset,\n",
    "            batch_size=dataset_opt[\"batch_size\"],\n",
    "            shuffle=dataset_opt[\"shuffle\"],\n",
    "            num_workers=dataset_opt[\"num_worker\"],\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "    elif phase in [\"val\", \"test\"]:  # validation\n",
    "        dataloader_args = dict(\n",
    "            dataset=dataset, batch_size=1, shuffle=False, num_workers=0\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Wrong dataset phase: {phase}. \"\n",
    "            \"Supported ones are 'train', 'val' and 'test'.\"\n",
    "        )\n",
    "\n",
    "    dataloader_args[\"pin_memory\"] = dataset_opt.get(\"pin_memory\", False)\n",
    "\n",
    "    #  prefetch_mode=None: Normal dataloader\n",
    "    # prefetch_mode='cuda': dataloader for CUDAPrefetcher\n",
    "    return DataLoader(**dataloader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "from torch import Tensor\n",
    "from typing import Any\n",
    "\n",
    "from src.lib.class_load import LoadFiles\n",
    "\n",
    "handler_files = LoadFiles()\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, dataset_path: Path | str, channel: int = 3, train: bool = True\n",
    "    ) -> None:\n",
    "        if train:\n",
    "            self.noisy_path = Path(dataset_path).joinpath(\"Noisy/train\") \n",
    "            self.gt_path = Path(dataset_path).joinpath(\"GTruth/train\")\n",
    "        else:\n",
    "            self.noisy_path = Path(dataset_path).joinpath(\"Noisy/test\") \n",
    "            self.gt_path = Path(dataset_path).joinpath(\"GTruth/test\")\n",
    "        self._noisy_images = handler_files.search_load_files_extencion(\n",
    "            path_search=self.noisy_path.as_posix(), ext=[\"png\"]\n",
    "        )[\"png\"][1]\n",
    "        self._gt_imges = handler_files.search_load_files_extencion(\n",
    "            path_search=self.gt_path.as_posix(), ext=[\"png\"]\n",
    "        )[\"png\"][1]\n",
    "        self.channel = channel\n",
    "\n",
    "    def __getitem__(self, index) -> dict[str, Any]:\n",
    "        if self.channel == 3:\n",
    "            img_gt: Tensor = read_image(\n",
    "                self._gt_imges[index], mode=ImageReadMode.RGB\n",
    "            )  # ImageReadMode.UNCHANGED\n",
    "            img_lq: Tensor = read_image(\n",
    "                self._noisy_images[index], mode=ImageReadMode.RGB\n",
    "            )\n",
    "        elif self.channel == 1:\n",
    "            img_gt: Tensor = read_image(\n",
    "                self._gt_imges[index], mode=ImageReadMode.GRAY\n",
    "            )\n",
    "            img_lq: Tensor = read_image(\n",
    "                self._noisy_images[index], mode=ImageReadMode.GRAY\n",
    "            )\n",
    "        return {\n",
    "            \"lq\": img_lq,\n",
    "            \"gt\": img_gt,\n",
    "            \"lq_path\": self._noisy_images[index],\n",
    "            \"gt_path\": self.gt_path[index],\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._noisy_images)\n",
    "\n",
    "\n",
    "# ImageReadMode.UNCHANGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def load_dataloader(opt):\n",
    "    if opt[\"dataloader\"][\"phase\"] == \"train\":\n",
    "        sar_dataset = CustomDataset(\n",
    "            dataset_path=opt[\"preprocessing\"][\"output\"], channel=3, train=True\n",
    "        )\n",
    "        dataloader = create_dataloader(\n",
    "            dataset=sar_dataset, dataset_opt=opt[\"dataloader\"]\n",
    "        )\n",
    "    elif opt[\"dataloader\"][\"phase\"] == \"val\":\n",
    "        sar_dataset = CustomDataset(\n",
    "            dataset_path=opt[\"preprocessing\"][\"output\"], channel=3, train=False\n",
    "        )\n",
    "        dataloader = create_dataloader(\n",
    "            dataset=sar_dataset,\n",
    "            dataset_opt=opt[\"dataloader\"],\n",
    "        )\n",
    "    num_iter_per_epoch = math.ceil(\n",
    "        len(sar_dataset)  / opt[\"dataloader\"][\"batch_size_per_gpu\"])\n",
    "    total_iters = int(opt[\"dataloader\"][\"iters\"])\n",
    "    total_epochs = math.ceil(total_iters / (num_iter_per_epoch))\n",
    "\n",
    "    return dataloader, total_epochs, total_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "file_config = Path(\n",
    "    \"/home/arthemis/Documents/pytorch_env/pytorch_env/transformers_ruben/src/data/config/config.yml\"\n",
    ")\n",
    "configuration = yaml.safe_load(file_config.open(\"r\"))\n",
    "\n",
    "dataloader_, total_epochs, total_iters = load_dataloader(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(dataloader_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if configuration[\"path\"][\"resume_state\"]:  # resume training\n",
    "    check_resume(opt, resume_state[\"iter\"])\n",
    "    model = create_model(opt)\n",
    "    model.resume_training(resume_state)  # handle optimizers and schedulers\n",
    "   \n",
    "    start_epoch = resume_state[\"epoch\"]\n",
    "    current_iter = resume_state[\"iter\"]\n",
    "else:\n",
    "    model = create_model(opt)\n",
    "    start_epoch = 0\n",
    "    current_iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from os import path as osp\n",
    "from basicsr.utils import scandir\n",
    "file_ = '/home/arthemis/Documents/pytorch_env/pytorch_env/transformers_ruben/basicsr/models/archs/__init__.py'\n",
    "\n",
    "arch_folder = osp.dirname(osp.abspath(file_))\n",
    "arch_filenames = [\n",
    "    osp.splitext(osp.basename(v))[0] for v in scandir(arch_folder)\n",
    "    if v.endswith('_arch.py')\n",
    "]\n",
    "# import all the arch modules\n",
    "_arch_modules = [\n",
    "    importlib.import_module(f'basicsr.models.archs.{file_name}')\n",
    "    for file_name in arch_filenames\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_arch_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_options():\n",
    "    import yaml\n",
    "    from pathlib import Path\n",
    "\n",
    "    file_config = Path(\n",
    "        \"/home/arthemis/Documents/pytorch_env/pytorch_env/transformers_ruben/src/data/config/config.yml\"\n",
    "    )\n",
    "    return yaml.safe_load(file_config.open(\"r\"))\n",
    "from basicsr.models.archs import define_network\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = parse_options()\n",
    "net = define_network(deepcopy(opt['network_g']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Module.get_parameter() missing 1 required positional argument: 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parameter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Module.get_parameter() missing 1 required positional argument: 'target'"
     ]
    }
   ],
   "source": [
    "net.get_parameter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16855780"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Restormer(\n",
       "  (patch_embed): OverlapPatchEmbed(\n",
       "    (proj): Conv2d(1, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (encoder_level1): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down1_2): Downsample(\n",
       "    (body): Sequential(\n",
       "      (0): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): PixelUnshuffle(downscale_factor=2)\n",
       "    )\n",
       "  )\n",
       "  (encoder_level2): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2_3): Downsample(\n",
       "    (body): Sequential(\n",
       "      (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): PixelUnshuffle(downscale_factor=2)\n",
       "    )\n",
       "  )\n",
       "  (encoder_level3): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3_4): Downsample(\n",
       "    (body): Sequential(\n",
       "      (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): PixelUnshuffle(downscale_factor=2)\n",
       "    )\n",
       "  )\n",
       "  (latent): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up4_3): Upsample(\n",
       "    (body): Sequential(\n",
       "      (0): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): PixelShuffle(upscale_factor=2)\n",
       "    )\n",
       "  )\n",
       "  (reduce_chan_level3): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (decoder_level3): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3_2): Upsample(\n",
       "    (body): Sequential(\n",
       "      (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): PixelShuffle(upscale_factor=2)\n",
       "    )\n",
       "  )\n",
       "  (reduce_chan_level2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (decoder_level2): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2_1): Upsample(\n",
       "    (body): Sequential(\n",
       "      (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): PixelShuffle(upscale_factor=2)\n",
       "    )\n",
       "  )\n",
       "  (decoder_level1): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (refinement): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): LayerNorm(\n",
       "        (body): BiasFree_LayerNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (project_in): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output): Conv2d(96, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env-VZ5w7g_q-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
