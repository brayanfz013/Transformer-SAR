{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "input_dir = \"/home/arthemis/Documents/pytorch_env/pytorch_env/transformers_ruben/src/data/transformed_data/Noisy/test\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7ArqQfvBbRf"
      },
      "source": [
        "# 4. Prepare Model and Load Checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDvxkztWDsYd"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "from runpy import run_path\n",
        "from skimage import img_as_ubyte\n",
        "from natsort import natsorted\n",
        "from glob import glob\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import argparse\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Cambiar cantidad de epoca de los pesos\n",
        "weights_available = list(range(4000, 84000, 4000))\n",
        "def get_weights_and_parameters(task, parameters):\n",
        "    if task == 'Real_Denoising':\n",
        "        # Si se quiere correr otro modelo se requiere cambiar el path\n",
        "        weights = [Path(f\"/home/arthemis/Documents/pytorch_env/pytorch_env/transformers_ruben/src/data/model/L1Loss_0_99/net_g_{w}.pth\") for w in weights_available]\n",
        "        parameters['LayerNorm_type'] =  'BiasFree'\n",
        "    return weights, parameters\n",
        "\n",
        "\n",
        "# Get model weights and parameters\n",
        "parameters = {'inp_channels':1, 'out_channels':1, 'dim':48, 'num_blocks':[4,6,6,8], 'num_refinement_blocks':4, 'heads':[1,2,4,8], 'ffn_expansion_factor':2.66, 'bias':False, 'LayerNorm_type':'WithBias', 'dual_pixel_task':False}\n",
        "task = \"Real_Denoising\"\n",
        "weights, parameters = get_weights_and_parameters(task, parameters)\n",
        "\n",
        "load_arch = run_path(os.path.join(\"/home\", \"arthemis\", \"Documents\", \"pytorch_env\", \"pytorch_env\", \"transformers_ruben\", \"basicsr\", \"models\", \"archs\",\"restormer_arch.py\"))\n",
        "model = load_arch['Restormer'](**parameters)\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "jm5gyBgzlONb",
        "outputId": "7096ccea-1b80-48ad-b3f0-c524238a4f83"
      },
      "outputs": [],
      "source": [
        "# 5. Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3yVqiRjflYll",
        "outputId": "f4f9bc27-e3b5-4fd5-b33e-11da7c60bc6d"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from numpy import float64\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import mean_squared_error as mse\n",
        "from collections import defaultdict\n",
        "\n",
        "#Datos de validacion articulo\n",
        "# input_dir = \"/home/arthemis/Documents/pytorch_env/pytorch_env/transformers_ruben/src/data/validation_data_report\"\n",
        "# noisy_dir = \"/home/arthemis/Documents/pytorch_env/pytorch_env/transformers_ruben/Uformer/images\"\n",
        "# out_dir = \"/home/arthemis/Documents/pytorch_env/pytorch_env/transformers_ruben/src/data/model/L1Loss_0_99/images\"\n",
        "\n",
        "#Datos de validacion de entrenamiento\n",
        "input_dir = \"/home/arthemis/Documents/pytorch_env/pytorch_env/transformers_ruben/src/data/transformed_data/val/groundtruth\"\n",
        "noisy_dir = \"/home/arthemis/Documents/pytorch_env/pytorch_env/transformers_ruben/src/data/transformed_data/val/input\"\n",
        "out_dir = \"/home/arthemis/Documents/pytorch_env/pytorch_env/transformers_ruben/src/data/model/L1Loss_0_99/images\"\n",
        "\n",
        "\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "extensions = [\"jpg\", \"JPG\", \"png\", \"PNG\", \"jpeg\", \"JPEG\", \"bmp\", \"BMP\"]\n",
        "# files = ['0_1024', '5120_19456','5120_19968','5120_20480']\n",
        "files = ['1536_2560_a', '2560_3584_a']\n",
        "\n",
        "\n",
        "img_multiple_of = 8\n",
        "\n",
        "print(f\"\\n ==> Running {task} with weights {weights}\\n \")\n",
        "metrics = defaultdict(list[dict[str, float | str | float64]])\n",
        "with torch.no_grad():\n",
        "    for weight, index in zip(weights, weights_available):\n",
        "        checkpoint = torch.load(weight)\n",
        "        model.load_state_dict(checkpoint[\"params\"])\n",
        "        model.eval()\n",
        "        for filepath in tqdm(files):\n",
        "            torch.cuda.ipc_collect()\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "\t\t\t#Noisy image input\n",
        "            im_path = \"/\".join((noisy_dir, f\"{filepath}.png\"))\n",
        "            og = cv2.imread(im_path,-1)\n",
        "            img = cv2.cvtColor(og, cv2.COLOR_BGR2GRAY)\n",
        "            img_ = np.reshape(img, (512, 512, 1))\n",
        "\n",
        "            input_ = torch.from_numpy(img_).float().permute(2, 0, 1).unsqueeze(0).cuda()\n",
        "            h, w = input_.shape[2], input_.shape[3]\n",
        "            H, W = (\n",
        "                ((h + img_multiple_of) // img_multiple_of) * img_multiple_of,\n",
        "                ((w + img_multiple_of) // img_multiple_of) * img_multiple_of,\n",
        "            )\n",
        "            padh = H - h if h % img_multiple_of != 0 else 0\n",
        "            padw = W - w if w % img_multiple_of != 0 else 0\n",
        "            input_ = F.pad(input_, (0, padw, 0, padh), \"reflect\")\n",
        "            restored = model(input_)\n",
        "            restored = restored[:, :, :h, :w]\n",
        "            restored = restored.permute(0, 2, 3, 1).cpu().detach().numpy()\n",
        "            restored = np.squeeze(restored[0])\n",
        "            \n",
        "            max_retormer = np.max(restored)\n",
        "            min_retormer = np.min(restored)            \n",
        "            \n",
        "            # Ground truth\n",
        "            val_im_path = \"/\".join((input_dir, f\"{filepath}.png\"))\n",
        "            val_og = cv2.imread(val_im_path,-1)\n",
        "            val_img = cv2.cvtColor(val_og, cv2.COLOR_BGR2GRAY)\n",
        "            \n",
        "            metrics[f\"model_{index}\"].append({\n",
        "\t\t\t\tf\"file_{filepath}\": \"\",\n",
        "\t\t\t\t\"psnr\": psnr(val_img.astype(np.float32), restored, data_range=max_retormer - min_retormer),\n",
        "\t\t\t\t\"ssim\": ssim(val_img.astype(np.float32), restored, data_range=max_retormer - min_retormer),\n",
        "\t\t\t\t\"mse\": mse(val_img.astype(np.float32), restored)\n",
        "\t\t\t})\n",
        "            filename = os.path.split(input_dir)[-1]\n",
        "            cv2.imwrite(os.path.join(out_dir, f\"{filepath}_{index}.png\"), restored)\n",
        "display(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYG9bFUSvEb8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
